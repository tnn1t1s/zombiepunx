{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "783de8ae-ec18-44e9-a015-086850d6913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Conv2DTranspose, Reshape\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "#import cv2\n",
    "import matplotlib.image as mpimg\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from re import sub\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b5e1e6f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('..')\n",
    "import utils as p"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99e488f",
   "metadata": {},
   "source": [
    "## load data and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "0b4e830a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/david/artwork/zombiepunx/data/punx/images/training/punk0000.png'"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def getPunkFilename(d, x):\n",
    "    return f'''{d}/punk{\"%04d\" % x.id}.png'''\n",
    "\n",
    "__ROOT_DIR__ = \"/home/david/artwork/zombiepunx\"\n",
    "__IMAGE_DIR__=f\"{__ROOT_DIR__}/data/punx/images/training\"\n",
    "df = pd.read_csv(f\"{__ROOT_DIR__}/data/punx/punks_df.csv\", index_col='pid')\n",
    "df['img_uri'] = df.agg(lambda x: getPunkFilename(__IMAGE_DIR__, x), axis=1)\n",
    "df.iloc[0].img_uri"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9e7a1b61",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>alien</th>\n",
       "      <th>ape</th>\n",
       "      <th>zombie</th>\n",
       "      <th>female</th>\n",
       "      <th>male</th>\n",
       "      <th>beanie</th>\n",
       "      <th>choker</th>\n",
       "      <th>pilotHelmet</th>\n",
       "      <th>tiara</th>\n",
       "      <th>...</th>\n",
       "      <th>bigShades</th>\n",
       "      <th>nerdGlasses</th>\n",
       "      <th>blackLipstick</th>\n",
       "      <th>mole</th>\n",
       "      <th>purpleLipstick</th>\n",
       "      <th>hotLipstick</th>\n",
       "      <th>cigarette</th>\n",
       "      <th>earring</th>\n",
       "      <th>straightHairDark</th>\n",
       "      <th>img_uri</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>pid</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>/home/david/artwork/zombiepunx/data/punx/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>/home/david/artwork/zombiepunx/data/punx/image...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>/home/david/artwork/zombiepunx/data/punx/image...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows Ã— 95 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     id  alien  ape  zombie  female  male  beanie  choker  pilotHelmet  tiara  \\\n",
       "pid                                                                             \n",
       "0     0   -1.0 -1.0    -1.0     1.0  -1.0    -1.0    -1.0         -1.0   -1.0   \n",
       "1     1   -1.0 -1.0    -1.0    -1.0   1.0    -1.0    -1.0         -1.0   -1.0   \n",
       "2     2   -1.0 -1.0    -1.0     1.0  -1.0    -1.0    -1.0         -1.0   -1.0   \n",
       "\n",
       "     ...  bigShades  nerdGlasses  blackLipstick  mole  purpleLipstick  \\\n",
       "pid  ...                                                                \n",
       "0    ...       -1.0         -1.0           -1.0  -1.0            -1.0   \n",
       "1    ...       -1.0         -1.0           -1.0  -1.0            -1.0   \n",
       "2    ...       -1.0         -1.0           -1.0  -1.0            -1.0   \n",
       "\n",
       "     hotLipstick  cigarette  earring  straightHairDark  \\\n",
       "pid                                                      \n",
       "0           -1.0       -1.0      1.0              -1.0   \n",
       "1           -1.0       -1.0     -1.0              -1.0   \n",
       "2           -1.0       -1.0     -1.0              -1.0   \n",
       "\n",
       "                                               img_uri  \n",
       "pid                                                     \n",
       "0    /home/david/artwork/zombiepunx/data/punx/image...  \n",
       "1    /home/david/artwork/zombiepunx/data/punx/image...  \n",
       "2    /home/david/artwork/zombiepunx/data/punx/image...  \n",
       "\n",
       "[3 rows x 95 columns]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "75d3c132",
   "metadata": {},
   "source": [
    "### GAN Hyperparameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "a464319e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "DIM = 24\n",
    "\n",
    "# size of noise vector\n",
    "LATENT_DIM_GAN = 24 \n",
    "\n",
    "# filter size in conv layer\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "# number of filters in conv layer\n",
    "NET_CAPACITY = 16\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE_GAN = 32\n",
    "\n",
    "# interval for displaying generated images\n",
    "PROGRESS_INTERVAL = 80 \n",
    "\n",
    "# number of discriminator updates per alternating training iteration\n",
    "DISC_UPDATES = 1  \n",
    "# number of generator updates per alternating training iteration\n",
    "GEN_UPDATES = 1 \n",
    "\n",
    "# directory for storing generated images\n",
    "ROOT_DIR = '../viz'\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    os.mkdir(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "4b5cdf11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24, 24, 1)"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p_9999 = p.get_punk(9999)\n",
    "p_9999_flat = p.flatten(p_9999)\n",
    "p_9999_encoded = p.v_color_map_encode(p_9999_flat)\n",
    "p_9999_encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "5644b77c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sample_punks(df, size):\n",
    "    samples = df.sample(frac=1).iloc[0:size]\n",
    "    X = np.empty(shape=(size, DIM, DIM, 1))\n",
    "    for i in range(0, size):\n",
    "        file = samples.iloc[i]\n",
    "        img = mpimg.imread(file.img_uri)\n",
    "        img_flat = p.flatten(img)\n",
    "        img_encoded = p.v_color_map_encode(img_flat)\n",
    "        X[i] = img_encoded\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "42481bdc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[220.],\n",
       "       [220.],\n",
       "       [220.],\n",
       "       [220.],\n",
       "       [220.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample_punks(df, 1)[0][0][0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "bd9a14a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(start_filters, filter_size, latent_dim):\n",
    "  \n",
    "  # function for building a CNN block for upsampling the image\n",
    "  def add_generator_block(x, filters, filter_size):\n",
    "      x = Conv2DTranspose(filters, filter_size, strides=2, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "\n",
    "  # input is a noise vector \n",
    "  inp = Input(shape=(latent_dim,))\n",
    "\n",
    "  # projection of the noise vector into a tensor with \n",
    "  # same shape as last conv layer in discriminator\n",
    "  x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
    "\n",
    "  # design the generator to upsample the image 4x\n",
    "  x = add_generator_block(x, start_filters * 4, filter_size)\n",
    "  x = add_generator_block(x, start_filters * 2, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)    \n",
    "\n",
    "  # turn the output into a 3D tensor, an image with 1 channels \n",
    "  x = Conv2D(1, kernel_size=5, padding='same', activation='tanh')(x)\n",
    "  \n",
    "  return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d2d42b",
   "metadata": {},
   "source": [
    "### discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "41e9030b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
    "    \n",
    "    # function for building a CNN block for downsampling the image\n",
    "    def add_discriminator_block(x, filters, filter_size):\n",
    "      x = Conv2D(filters, filter_size, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "    \n",
    "    # input is an image with shape spatial_dim x spatial_dim and 1 channels\n",
    "    inp = Input(shape=(spatial_dim, spatial_dim, 1))\n",
    "\n",
    "    #  to downsample the image 4x\n",
    "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
    "    \n",
    "    # average and return a binary output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac96607",
   "metadata": {},
   "source": [
    "## build GAN from generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "f6255c91",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 24, 24, 1) for input KerasTensor(type_spec=TensorSpec(shape=(None, 24, 24, 1), dtype=tf.float32, name='input_3'), name='input_3', description=\"created by layer 'input_3'\"), but it was called on an input with incompatible shape (None, 64, 64, 1).\n",
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_4 (InputLayer)         [(None, 24)]              0         \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 2048)              51200     \n",
      "_________________________________________________________________\n",
      "batch_normalization_21 (Batc (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "reshape_1 (Reshape)          (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTr (None, 8, 8, 64)          204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_22 (Batc (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_12 (LeakyReLU)   (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_5 (Conv2DTr (None, 16, 16, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_23 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_13 (LeakyReLU)   (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_6 (Conv2DTr (None, 32, 32, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_24 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_14 (LeakyReLU)   (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_7 (Conv2DTr (None, 64, 64, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_25 (Batc (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_15 (LeakyReLU)   (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_17 (Conv2D)           (None, 64, 64, 1)         401       \n",
      "=================================================================\n",
      "Total params: 335,633\n",
      "Trainable params: 331,281\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n",
      "Model: \"model_2\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_3 (InputLayer)         [(None, 24, 24, 1)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d_9 (Conv2D)            (None, 24, 24, 16)        416       \n",
      "_________________________________________________________________\n",
      "batch_normalization_13 (Batc (None, 24, 24, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_10 (Conv2D)           (None, 12, 12, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_14 (Batc (None, 12, 12, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_8 (LeakyReLU)    (None, 12, 12, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_11 (Conv2D)           (None, 12, 12, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_15 (Batc (None, 12, 12, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_12 (Conv2D)           (None, 6, 6, 32)          25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_16 (Batc (None, 6, 6, 32)          128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_9 (LeakyReLU)    (None, 6, 6, 32)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_13 (Conv2D)           (None, 6, 6, 64)          51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_17 (Batc (None, 6, 6, 64)          256       \n",
      "_________________________________________________________________\n",
      "conv2d_14 (Conv2D)           (None, 3, 3, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_18 (Batc (None, 3, 3, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_10 (LeakyReLU)   (None, 3, 3, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_15 (Conv2D)           (None, 3, 3, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_19 (Batc (None, 3, 3, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_16 (Conv2D)           (None, 2, 2, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_20 (Batc (None, 2, 2, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_11 (LeakyReLU)   (None, 2, 2, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d_1 ( (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_2 (Dense)              (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 815,729\n",
      "Trainable params: 0\n",
      "Non-trainable params: 815,729\n",
      "_________________________________________________________________\n",
      "Model: \"sequential_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_3 (Functional)         (None, 64, 64, 1)         335633    \n",
      "_________________________________________________________________\n",
      "model_2 (Functional)         (None, 1)                 815729    \n",
      "=================================================================\n",
      "Total params: 1,151,362\n",
      "Trainable params: 331,281\n",
      "Non-trainable params: 820,081\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def construct_models(verbose=False):\n",
    "    ### discriminator\n",
    "    discriminator = build_discriminator(NET_CAPACITY, DIM, FILTER_SIZE)\n",
    "    # compile discriminator\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=Adam(lr=0.0002), \n",
    "                          metrics=['mae'])\n",
    "\n",
    "    ### generator\n",
    "    # do not compile generator\n",
    "    generator = build_generator(NET_CAPACITY, FILTER_SIZE, LATENT_DIM_GAN)\n",
    "\n",
    "    ### DCGAN \n",
    "    gan = Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    discriminator.trainable = False \n",
    "    gan.compile(loss='binary_crossentropy', \n",
    "                optimizer=Adam(lr=0.0002), \n",
    "                metrics=['mae'])\n",
    "\n",
    "    if verbose: \n",
    "        generator.summary()\n",
    "        discriminator.summary()\n",
    "        gan.summary()\n",
    "        \n",
    "    return generator, discriminator, gan\n",
    "  \n",
    "(generator_punk, \n",
    "discriminator_punk,\n",
    "gan_punk) = construct_models(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec68e094",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa301929",
   "metadata": {},
   "source": [
    "ref: https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "b833e7c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(generator, \n",
    "                 discriminator, \n",
    "                 gan, \n",
    "                 df, start_it=0, \n",
    "                 num_epochs=1000, \n",
    "                 get_real_images=sample_punks):\n",
    "  # list for storing loss\n",
    "  avg_loss_discriminator = []\n",
    "  avg_loss_generator = []\n",
    "  total_it = start_it\n",
    "\n",
    "  # main training loop\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "      # alternating training loop\n",
    "      loss_discriminator = []\n",
    "      loss_generator = []\n",
    "      for it in range(200): \n",
    "\n",
    "          #### Discriminator training loop ####\n",
    "          for i in range(DISC_UPDATES): \n",
    "              # select a random set of real images\n",
    "              imgs_real = get_real_images(df, BATCH_SIZE_GAN)\n",
    "              # generate a set of random noise vectors\n",
    "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # generate a set of fake images using the generator\n",
    "              imgs_fake = generator.predict(noise)\n",
    "              # train the discriminator on real images with label 1\n",
    "              d_loss_real = discriminator.train_on_batch(imgs_real, \n",
    "                                                         np.ones([BATCH_SIZE_GAN]))[1]\n",
    "              # train the discriminator on fake images with label 0\n",
    "              d_loss_fake = discriminator.train_on_batch(imgs_fake, \n",
    "                                                         np.zeros([BATCH_SIZE_GAN]))[1]\n",
    "\n",
    "          # display some fake images for visual control of convergence\n",
    "          if total_it % PROGRESS_INTERVAL == 0:\n",
    "              plt.figure(figsize=(5,2))\n",
    "              num_vis = min(BATCH_SIZE_GAN, 5)\n",
    "              imgs_real = get_real_images(df, num_vis)\n",
    "              noise = np.random.randn(num_vis, LATENT_DIM_GAN)\n",
    "              imgs_fake = generator.predict(noise)\n",
    "              for obj_plot in [imgs_fake, imgs_real]:\n",
    "                  plt.figure(figsize=(num_vis * 3, 3))\n",
    "                  for b in range(num_vis):\n",
    "                      disc_score = float(discriminator.predict(np.expand_dims(obj_plot[b], axis=0))[0])\n",
    "                      plt.subplot(1, num_vis, b + 1)\n",
    "                      plt.title(str(round(disc_score, 3)))\n",
    "                      plt.imshow(obj_plot[b] * 0.5 + 0.5) \n",
    "                  if obj_plot is imgs_fake:\n",
    "                      plt.savefig(os.path.join(ROOT_DIR, \n",
    "                                               str(total_it).zfill(10) + '.jpg'), \n",
    "                                  format='jpg',\n",
    "                                  bbox_inches='tight')\n",
    "                  plt.show()  \n",
    "\n",
    "          #### Generator training loop ####\n",
    "          loss = 0\n",
    "          y = np.ones([BATCH_SIZE_GAN, 1]) \n",
    "          for j in range(GEN_UPDATES):\n",
    "              # generate a set of random noise vectors\n",
    "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # train the generator on fake images with label 1\n",
    "              loss += gan.train_on_batch(noise, y)[1]\n",
    "\n",
    "          # store loss\n",
    "          loss_discriminator.append((d_loss_real + d_loss_fake) / 2.)        \n",
    "          loss_generator.append(loss / GEN_UPDATES)\n",
    "          total_it += 1\n",
    "\n",
    "      # visualize loss\n",
    "      clear_output(True)\n",
    "      print('Epoch', epoch)\n",
    "      avg_loss_discriminator.append(np.mean(loss_discriminator))\n",
    "      avg_loss_generator.append(np.mean(loss_generator))\n",
    "      plt.plot(range(len(avg_loss_discriminator)), avg_loss_discriminator)\n",
    "      plt.plot(range(len(avg_loss_generator)), avg_loss_generator)\n",
    "      plt.legend(['discriminator loss', 'generator loss'])\n",
    "      plt.show()\n",
    "\n",
    "  return generator, discriminator, gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "eafe29cf",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "in user code:\n\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_2: expected shape=(None, 24, 24, 1), found shape=(32, 64, 64, 1)\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m--------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m             Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-75-c18381f9e3fc>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m (generator_punk,\n\u001b[1;32m      2\u001b[0m  \u001b[0mdiscriminator_punk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m  \u001b[0mgan_punk\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mrun_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgenerator_punk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m                           \u001b[0mdiscriminator_punk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m                           \u001b[0mgan_punk\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-74-1d8493d7fa57>\u001b[0m in \u001b[0;36mrun_training\u001b[0;34m(generator, discriminator, gan, df, start_it, num_epochs, get_real_images)\u001b[0m\n\u001b[1;32m     30\u001b[0m                                                          np.ones([BATCH_SIZE_GAN]))[1]\n\u001b[1;32m     31\u001b[0m               \u001b[0;31m# train the discriminator on fake images with label 0\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m               d_loss_fake = discriminator.train_on_batch(imgs_fake, \n\u001b[0m\u001b[1;32m     33\u001b[0m                                                          np.zeros([BATCH_SIZE_GAN]))[1]\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[0;34m(self, x, y, sample_weight, class_weight, reset_metrics, return_dict)\u001b[0m\n\u001b[1;32m   1725\u001b[0m                                                     class_weight)\n\u001b[1;32m   1726\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_train_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1727\u001b[0;31m       \u001b[0mlogs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_function\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1728\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1729\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    826\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    827\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mtrace\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTrace\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 828\u001b[0;31m       \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    829\u001b[0m       \u001b[0mcompiler\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m\"xla\"\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_experimental_compile\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m\"nonXla\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    830\u001b[0m       \u001b[0mnew_tracing_count\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperimental_get_tracing_count\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, *args, **kwds)\u001b[0m\n\u001b[1;32m    853\u001b[0m       \u001b[0;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    854\u001b[0m       \u001b[0;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 855\u001b[0;31m       \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# pylint: disable=not-callable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    856\u001b[0m     \u001b[0;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    857\u001b[0m       \u001b[0;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   2939\u001b[0m     \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2940\u001b[0m       (graph_function,\n\u001b[0;32m-> 2941\u001b[0;31m        filtered_flat_args) = self._maybe_define_function(args, kwargs)\n\u001b[0m\u001b[1;32m   2942\u001b[0m     return graph_function._call_flat(\n\u001b[1;32m   2943\u001b[0m         filtered_flat_args, captured_inputs=graph_function.captured_inputs)  # pylint: disable=protected-access\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_maybe_define_function\u001b[0;34m(self, args, kwargs)\u001b[0m\n\u001b[1;32m   3355\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minput_signature\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3356\u001b[0m               call_context_key in self._function_cache.missed):\n\u001b[0;32m-> 3357\u001b[0;31m             return self._define_function_with_shape_relaxation(\n\u001b[0m\u001b[1;32m   3358\u001b[0m                 args, kwargs, flat_args, filtered_flat_args, cache_key_context)\n\u001b[1;32m   3359\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_define_function_with_shape_relaxation\u001b[0;34m(self, args, kwargs, flat_args, filtered_flat_args, cache_key_context)\u001b[0m\n\u001b[1;32m   3277\u001b[0m           expand_composites=True)\n\u001b[1;32m   3278\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3279\u001b[0;31m     graph_function = self._create_graph_function(\n\u001b[0m\u001b[1;32m   3280\u001b[0m         args, kwargs, override_flat_arg_shapes=relaxed_arg_shapes)\n\u001b[1;32m   3281\u001b[0m     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_function_cache\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marg_relaxed\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mrank_only_cache_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/function.py\u001b[0m in \u001b[0;36m_create_graph_function\u001b[0;34m(self, args, kwargs, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m   3194\u001b[0m     \u001b[0marg_names\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbase_arg_names\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0mmissing_arg_names\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3195\u001b[0m     graph_function = ConcreteFunction(\n\u001b[0;32m-> 3196\u001b[0;31m         func_graph_module.func_graph_from_py_func(\n\u001b[0m\u001b[1;32m   3197\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_name\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3198\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_python_function\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mfunc_graph_from_py_func\u001b[0;34m(name, python_func, args, kwargs, signature, func_graph, autograph, autograph_options, add_control_dependencies, arg_names, op_return_value, collections, capture_by_value, override_flat_arg_shapes)\u001b[0m\n\u001b[1;32m    988\u001b[0m         \u001b[0m_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moriginal_func\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_decorator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munwrap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpython_func\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    989\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 990\u001b[0;31m       \u001b[0mfunc_outputs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpython_func\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mfunc_args\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mfunc_kwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    991\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    992\u001b[0m       \u001b[0;31m# invariant: `func_outputs` contains only Tensors, CompositeTensors,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/eager/def_function.py\u001b[0m in \u001b[0;36mwrapped_fn\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    632\u001b[0m             \u001b[0mxla_context\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mExit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m           \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mweak_wrapped_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__wrapped__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    636\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/framework/func_graph.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    975\u001b[0m           \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# pylint:disable=broad-except\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    976\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mhasattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"ag_error_metadata\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 977\u001b[0;31m               \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mag_error_metadata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_exception\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    978\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    979\u001b[0m               \u001b[0;32mraise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: in user code:\n\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:805 train_function  *\n        return step_function(self, iterator)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:795 step_function  **\n        outputs = model.distribute_strategy.run(run_step, args=(data,))\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:1259 run\n        return self._extended.call_for_each_replica(fn, args=args, kwargs=kwargs)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:2730 call_for_each_replica\n        return self._call_for_each_replica(fn, args, kwargs)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/distribute/distribute_lib.py:3417 _call_for_each_replica\n        return fn(*args, **kwargs)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:788 run_step  **\n        outputs = model.train_step(data)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/training.py:754 train_step\n        y_pred = self(x, training=True)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/base_layer.py:998 __call__\n        input_spec.assert_input_compatibility(self.input_spec, inputs, self.name)\n    /home/david/miniconda3/envs/zombiepunx/lib/python3.8/site-packages/tensorflow/python/keras/engine/input_spec.py:271 assert_input_compatibility\n        raise ValueError('Input ' + str(input_index) +\n\n    ValueError: Input 0 is incompatible with layer model_2: expected shape=(None, 24, 24, 1), found shape=(32, 64, 64, 1)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "(generator_punk,\n",
    " discriminator_punk,\n",
    " gan_punk) = run_training(generator_punk,\n",
    "                          discriminator_punk,\n",
    "                          gan_punk,\n",
    "                          num_epochs=5,\n",
    "                          df=df)                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "0baa8ee4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7fe7587893a0>"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_punk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

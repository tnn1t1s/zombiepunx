{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "783de8ae-ec18-44e9-a015-086850d6913b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.layers import Conv2D, BatchNormalization, Input, GlobalAveragePooling2D, Dense\n",
    "from keras.models import Model, Sequential\n",
    "from keras.layers.advanced_activations import LeakyReLU\n",
    "from keras.layers import Conv2DTranspose, Reshape\n",
    "\n",
    "import pandas as pd\n",
    "import os\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from IPython.display import clear_output\n",
    "\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5115ac9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import requests\n",
    "from re import sub"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "3bd6159c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# function to convert string to camelCase\n",
    "def camelCase(string):\n",
    "  string = sub(r\"(_|-)+\", \" \", string).title().replace(\" \", \"\")\n",
    "  return string[0].lower() + string[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "da8a7597",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['bandana', 'regularShades']"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "typeClass=\"col-md-10 col-md-offset-1 col-xs-12\"\n",
    "punk_html=requests.get('https://www.larvalabs.com/cryptopunks/details/635').text\n",
    "soup = BeautifulSoup(punk_html, 'html.parser')\n",
    "details = soup.find(id=\"punkDetails\")\n",
    "\n",
    "punkType = camelCase(details.find(class_=typeClass).find('a').contents[0])\n",
    "\n",
    "attrs=[]\n",
    "attrTags = details.find(class_ = \"row detail-row\")\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "0d009021",
   "metadata": {},
   "outputs": [],
   "source": [
    "# build default attr dictionary\n",
    "d={}\n",
    "with open(f\"{__ROOT_DIR__}/data/punx/list_attr_punx.csv\") as f:\n",
    "    for attr in f.read().split(','):\n",
    "        d[attr]=-1\n",
    "        \n",
    "\n",
    "for attrTag in attrTags.find_all('a'):\n",
    "    d[camelCase(attrTag.contents[0])]=1\n",
    "d[punkType]=1 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "141313da",
   "metadata": {},
   "outputs": [],
   "source": [
    "__ROOT_DIR__ = \"/home/david/artwork/zombiepunx\"\n",
    "IMAGE_DIR=f\"{__ROOT_DIR__}/data/celeb/img_align_celeba/\"\n",
    "df = pd.read_csv('../data/celeb/list_attr_celeba.csv')\n",
    "df['img_uri'] = IMAGE_DIR + df['image_id']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6828ad7d",
   "metadata": {},
   "source": [
    "## load data and setup environment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "81ae4b27",
   "metadata": {},
   "outputs": [],
   "source": [
    "__ROOT_DIR__ = \"/home/david/artwork/zombiepunx\"\n",
    "IMAGE_DIR=f\"{__ROOT_DIR__}/data/celeb/img_align_celeba/\"\n",
    "df = pd.read_csv('../data/celeb/list_attr_celeba.csv')\n",
    "df['img_uri'] = IMAGE_DIR + df['image_id']\n",
    "\n",
    "\n",
    "TOTAL_SAMPLES = df.shape[0]\n",
    "\n",
    "SPATIAL_DIM = 24\n",
    "\n",
    "# size of noise vector\n",
    "LATENT_DIM_GAN = 100 \n",
    "\n",
    "# filter size in conv layer\n",
    "FILTER_SIZE = 5\n",
    "\n",
    "# number of filters in conv layer\n",
    "NET_CAPACITY = 16\n",
    "\n",
    "# batch size\n",
    "BATCH_SIZE_GAN = 32\n",
    "\n",
    "# interval for displaying generated images\n",
    "PROGRESS_INTERVAL = 80 \n",
    "\n",
    "# directory for storing generated images\n",
    "ROOT_DIR = '../viz'\n",
    "if not os.path.isdir(ROOT_DIR):\n",
    "    os.mkdir(ROOT_DIR)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f6386ef6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# helper function for selecting 'size' real images\n",
    "# and downscaling them to lower dimension SPATIAL_DIM\n",
    "def sample_punks(df, size):\n",
    "    samples = df.sample(frac=1).iloc[0:size]\n",
    "    X = np.empty(shape=(size, SPATIAL_DIM, SPATIAL_DIM, 3))\n",
    "    for i in range(0, size):\n",
    "        file = samples.iloc[i]\n",
    "        img_uri = file.img_uri\n",
    "        img = cv2.imread(img_uri)\n",
    "        img = np.flip(img, axis=2)\n",
    "        img = img.astype(np.float32) / 127.5 - 1.0\n",
    "        X[i] = img\n",
    "    return X"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d11cda69",
   "metadata": {},
   "source": [
    "\n",
    "# function for building the discriminator layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "61936f6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_discriminator(start_filters, spatial_dim, filter_size):\n",
    "    \n",
    "    # function for building a CNN block for downsampling the image\n",
    "    def add_discriminator_block(x, filters, filter_size):\n",
    "      x = Conv2D(filters, filter_size, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = Conv2D(filters, filter_size, padding='same', strides=2)(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "    \n",
    "    # input is an image with shape spatial_dim x spatial_dim and 1 channels\n",
    "    inp = Input(shape=(spatial_dim, spatial_dim, 1))\n",
    "\n",
    "    # design the discrimitor to downsample the image 4x\n",
    "    x = add_discriminator_block(inp, start_filters, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 2, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 4, filter_size)\n",
    "    x = add_discriminator_block(x, start_filters * 8, filter_size)\n",
    "    \n",
    "    # average and return a binary output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1, activation='sigmoid')(x)\n",
    "    \n",
    "    return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "d8293c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def build_generator(start_filters, filter_size, latent_dim):\n",
    "  \n",
    "  # function for building a CNN block for upsampling the image\n",
    "  def add_generator_block(x, filters, filter_size):\n",
    "      x = Conv2DTranspose(filters, filter_size, strides=2, padding='same')(x)\n",
    "      x = BatchNormalization()(x)\n",
    "      x = LeakyReLU(0.3)(x)\n",
    "      return x\n",
    "\n",
    "  # input is a noise vector \n",
    "  inp = Input(shape=(latent_dim,))\n",
    "\n",
    "  # projection of the noise vector into a tensor with \n",
    "  # same shape as last conv layer in discriminator\n",
    "  x = Dense(4 * 4 * (start_filters * 8), input_dim=latent_dim)(inp)\n",
    "  x = BatchNormalization()(x)\n",
    "  x = Reshape(target_shape=(4, 4, start_filters * 8))(x)\n",
    "\n",
    "  # design the generator to upsample the image 4x\n",
    "  x = add_generator_block(x, start_filters * 4, filter_size)\n",
    "  x = add_generator_block(x, start_filters * 2, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)\n",
    "  x = add_generator_block(x, start_filters, filter_size)    \n",
    "\n",
    "  # turn the output into a 3D tensor, an image with 1 channels \n",
    "  x = Conv2D(1, kernel_size=5, padding='same', activation='tanh')(x)\n",
    "  \n",
    "  return Model(inputs=inp, outputs=x)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "233d12ef",
   "metadata": {},
   "source": [
    "## build GAN from generator and discriminator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "630aa4b1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_1\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_2 (InputLayer)         [(None, 100)]             0         \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 2048)              206848    \n",
      "_________________________________________________________________\n",
      "batch_normalization_8 (Batch (None, 2048)              8192      \n",
      "_________________________________________________________________\n",
      "reshape (Reshape)            (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose (Conv2DTran (None, 8, 8, 64)          204864    \n",
      "_________________________________________________________________\n",
      "batch_normalization_9 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_4 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTr (None, 16, 16, 32)        51232     \n",
      "_________________________________________________________________\n",
      "batch_normalization_10 (Batc (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_5 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTr (None, 32, 32, 16)        12816     \n",
      "_________________________________________________________________\n",
      "batch_normalization_11 (Batc (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_6 (LeakyReLU)    (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTr (None, 64, 64, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_12 (Batc (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_7 (LeakyReLU)    (None, 64, 64, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_8 (Conv2D)            (None, 64, 64, 3)         1203      \n",
      "=================================================================\n",
      "Total params: 492,083\n",
      "Trainable params: 487,731\n",
      "Non-trainable params: 4,352\n",
      "_________________________________________________________________\n",
      "Model: \"model\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "input_1 (InputLayer)         [(None, 64, 64, 3)]       0         \n",
      "_________________________________________________________________\n",
      "conv2d (Conv2D)              (None, 64, 64, 16)        1216      \n",
      "_________________________________________________________________\n",
      "batch_normalization (BatchNo (None, 64, 64, 16)        64        \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 32, 32, 16)        6416      \n",
      "_________________________________________________________________\n",
      "batch_normalization_1 (Batch (None, 32, 32, 16)        64        \n",
      "_________________________________________________________________\n",
      "leaky_re_lu (LeakyReLU)      (None, 32, 32, 16)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 32, 32, 32)        12832     \n",
      "_________________________________________________________________\n",
      "batch_normalization_2 (Batch (None, 32, 32, 32)        128       \n",
      "_________________________________________________________________\n",
      "conv2d_3 (Conv2D)            (None, 16, 16, 32)        25632     \n",
      "_________________________________________________________________\n",
      "batch_normalization_3 (Batch (None, 16, 16, 32)        128       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_1 (LeakyReLU)    (None, 16, 16, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_4 (Conv2D)            (None, 16, 16, 64)        51264     \n",
      "_________________________________________________________________\n",
      "batch_normalization_4 (Batch (None, 16, 16, 64)        256       \n",
      "_________________________________________________________________\n",
      "conv2d_5 (Conv2D)            (None, 8, 8, 64)          102464    \n",
      "_________________________________________________________________\n",
      "batch_normalization_5 (Batch (None, 8, 8, 64)          256       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_2 (LeakyReLU)    (None, 8, 8, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_6 (Conv2D)            (None, 8, 8, 128)         204928    \n",
      "_________________________________________________________________\n",
      "batch_normalization_6 (Batch (None, 8, 8, 128)         512       \n",
      "_________________________________________________________________\n",
      "conv2d_7 (Conv2D)            (None, 4, 4, 128)         409728    \n",
      "_________________________________________________________________\n",
      "batch_normalization_7 (Batch (None, 4, 4, 128)         512       \n",
      "_________________________________________________________________\n",
      "leaky_re_lu_3 (LeakyReLU)    (None, 4, 4, 128)         0         \n",
      "_________________________________________________________________\n",
      "global_average_pooling2d (Gl (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense (Dense)                (None, 1)                 129       \n",
      "=================================================================\n",
      "Total params: 816,529\n",
      "Trainable params: 0\n",
      "Non-trainable params: 816,529\n",
      "_________________________________________________________________\n",
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "model_1 (Functional)         (None, 64, 64, 3)         492083    \n",
      "_________________________________________________________________\n",
      "model (Functional)           (None, 1)                 816529    \n",
      "=================================================================\n",
      "Total params: 1,308,612\n",
      "Trainable params: 487,731\n",
      "Non-trainable params: 820,881\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def construct_models(verbose=False):\n",
    "    ### discriminator\n",
    "    discriminator = build_discriminator(NET_CAPACITY, SPATIAL_DIM, FILTER_SIZE)\n",
    "    # compile discriminator\n",
    "    discriminator.compile(loss='binary_crossentropy', \n",
    "                          optimizer=Adam(lr=0.0002), \n",
    "                          metrics=['mae'])\n",
    "\n",
    "    ### generator\n",
    "    # do not compile generator\n",
    "    generator = build_generator(NET_CAPACITY, FILTER_SIZE, LATENT_DIM_GAN)\n",
    "\n",
    "    ### DCGAN \n",
    "    gan = Sequential()\n",
    "    gan.add(generator)\n",
    "    gan.add(discriminator)\n",
    "    discriminator.trainable = False \n",
    "    gan.compile(loss='binary_crossentropy', \n",
    "                optimizer=Adam(lr=0.0002), \n",
    "                metrics=['mae'])\n",
    "\n",
    "    if verbose: \n",
    "        generator.summary()\n",
    "        discriminator.summary()\n",
    "        gan.summary()\n",
    "        \n",
    "    return generator, discriminator, gan\n",
    "  \n",
    "(generator_punk, \n",
    "discriminator_punk,\n",
    "gan_punk) = construct_models(verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4f93ee7",
   "metadata": {},
   "source": [
    "# Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "07820192",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# number of discriminator updates per alternating training iteration\n",
    "DISC_UPDATES = 1  \n",
    "# number of generator updates per alternating training iteration\n",
    "GEN_UPDATES = 1 "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3440db63",
   "metadata": {},
   "source": [
    "# function for training the GAN"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0fc75cec",
   "metadata": {},
   "source": [
    "ref: https://towardsdatascience.com/generative-adversarial-network-gan-for-dummies-a-step-by-step-tutorial-fdefff170391"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "5698a406",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_training(generator, \n",
    "                 discriminator, \n",
    "                 gan, \n",
    "                 df, start_it=0, \n",
    "                 num_epochs=1000, \n",
    "                 get_real_images=sample_punks):\n",
    "  # list for storing loss\n",
    "  avg_loss_discriminator = []\n",
    "  avg_loss_generator = []\n",
    "  total_it = start_it\n",
    "\n",
    "  # main training loop\n",
    "  for epoch in range(num_epochs):\n",
    "\n",
    "      # alternating training loop\n",
    "      loss_discriminator = []\n",
    "      loss_generator = []\n",
    "      for it in range(200): \n",
    "\n",
    "          #### Discriminator training loop ####\n",
    "          for i in range(DISC_UPDATES): \n",
    "              print(i)\n",
    "              # select a random set of real images\n",
    "              imgs_real = get_real_images(df, BATCH_SIZE_GAN)\n",
    "              # generate a set of random noise vectors\n",
    "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # generate a set of fake images using the generator\n",
    "              imgs_fake = generator.predict(noise)\n",
    "              # train the discriminator on real images with label 1\n",
    "              d_loss_real = discriminator.train_on_batch(imgs_real, \n",
    "                                                         np.ones([BATCH_SIZE_GAN]))[1]\n",
    "              # train the discriminator on fake images with label 0\n",
    "              d_loss_fake = discriminator.train_on_batch(imgs_fake, \n",
    "                                                         np.zeros([BATCH_SIZE_GAN]))[1]\n",
    "\n",
    "          # display some fake images for visual control of convergence\n",
    "          if total_it % PROGRESS_INTERVAL == 0:\n",
    "              plt.figure(figsize=(5,2))\n",
    "              num_vis = min(BATCH_SIZE_GAN, 5)\n",
    "              imgs_real = get_real_images(df, num_vis)\n",
    "              noise = np.random.randn(num_vis, LATENT_DIM_GAN)\n",
    "              imgs_fake = generator.predict(noise)\n",
    "              for obj_plot in [imgs_fake, imgs_real]:\n",
    "                  plt.figure(figsize=(num_vis * 3, 3))\n",
    "                  for b in range(num_vis):\n",
    "                      disc_score = float(discriminator.predict(np.expand_dims(obj_plot[b], axis=0))[0])\n",
    "                      plt.subplot(1, num_vis, b + 1)\n",
    "                      plt.title(str(round(disc_score, 3)))\n",
    "                      plt.imshow(obj_plot[b] * 0.5 + 0.5) \n",
    "                  if obj_plot is imgs_fake:\n",
    "                      plt.savefig(os.path.join(ROOT_DIR, \n",
    "                                               str(total_it).zfill(10) + '.jpg'), \n",
    "                                  format='jpg',\n",
    "                                  bbox_inches='tight')\n",
    "                  plt.show()  \n",
    "\n",
    "          #### Generator training loop ####\n",
    "          loss = 0\n",
    "          y = np.ones([BATCH_SIZE_GAN, 1]) \n",
    "          for j in range(GEN_UPDATES):\n",
    "              # generate a set of random noise vectors\n",
    "              noise = np.random.randn(BATCH_SIZE_GAN, LATENT_DIM_GAN)\n",
    "              # train the generator on fake images with label 1\n",
    "              loss += gan.train_on_batch(noise, y)[1]\n",
    "\n",
    "          # store loss\n",
    "          loss_discriminator.append((d_loss_real + d_loss_fake) / 2.)        \n",
    "          loss_generator.append(loss / GEN_UPDATES)\n",
    "          total_it += 1\n",
    "\n",
    "      # visualize loss\n",
    "      clear_output(True)\n",
    "      print('Epoch', epoch)\n",
    "      avg_loss_discriminator.append(np.mean(loss_discriminator))\n",
    "      avg_loss_generator.append(np.mean(loss_generator))\n",
    "      plt.plot(range(len(avg_loss_discriminator)), avg_loss_discriminator)\n",
    "      plt.plot(range(len(avg_loss_generator)), avg_loss_generator)\n",
    "      plt.legend(['discriminator loss', 'generator loss'])\n",
    "      plt.show()\n",
    "\n",
    "  return generator, discriminator, gan\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "789d692c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "(generator_punk,\n",
    " discriminator_punk,\n",
    " gan_punk) = run_training(generator_punk,\n",
    "                          discriminator_punk,\n",
    "                          gan_punk,\n",
    "                          num_epochs=5,\n",
    "                          df=df)                                                 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b5eb48e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.engine.functional.Functional at 0x7fe75786fa30>"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "generator_punk"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
